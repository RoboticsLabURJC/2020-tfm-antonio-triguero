---
title: "Restarting"
date: 2022-06-23T22:15:00-04:00
categories:
  - logbook
tags:
  - log
  - update
---

Since these two weeks I was working in check my gazebo gym environments implementations and I thought that I was getting complicated because with catkin workspace it's so easy to launch a file from jderobots.

I was refactoring my code and I build a new gazebo gym environment, Montmelo Line. After that, I was working in Q learning implementation and choosing reward, observation and done functions.

### Observation function

For observation I use the area between the line of the image center and the skinny line of the road. I discretize this area with integer values. The are can be negative (left side) or positive (right side).

### Reward function

For reward, first, I was using one when the car follow the line and zero when car cross the line. At this moment, the enviroment throw done signal and the environment is restarted.

After check that function and see that it wasn't working, I think that can be better to penalize very hard the agent when he makes a mistake. For this reason, I chose -10000 when cross the line and 1 when follow the line.

### Done function

Done is true when agent cross the line.

### Results

With these functions the agent can follow the line but it can't take curves. I think that the observation function isn't good for this environment. Next days I am going to follow the observation function from Ignacio and using it for my environment. 
