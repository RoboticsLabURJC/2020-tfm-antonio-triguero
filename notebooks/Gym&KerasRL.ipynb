{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gym&KerasRL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRGs8qDAOh11"
      },
      "source": [
        "# Introduction\r\n",
        "\r\n",
        "This notebook try to show how to use **Open AI Gym** on Jupyter an Google Colaboratory and combine it with Keras-rl for implement agents that use different kinds of algorithms for resolving the enviroment selected on Open AI Gym.\r\n",
        "\r\n",
        "**Keras-rl** is a framework of reinforcement learning that give us the possiblity of build a RL agents similar when we build a model on **Keras**. You select the agent, build it (this need a model of Keras as argument) and train it from environment build on gym.\r\n",
        "\r\n",
        "This notebook us packages for rendering the Open AI Gym results on Jupyter and **Google Colab**. The main package in **gnwrapper** that implement wrappers for gym environments that offer different possibilities for rendering the results. The wrapper used in this notebook is Monitor that save the result in video format and we can render these in the notebook with the display function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0KIcZz-bvTG"
      },
      "source": [
        "# Setup\r\n",
        "\r\n",
        "We need to download and install packages needed for rendering the results and implement different models of reinforcement learning. \r\n",
        "\r\n",
        "After that, we have to import gym. numpy, keras, keras-rl and other packages used on this notebook. Something very important is to install specific versions of tensorflow, keras, and keras-rl because the last has dependencies from the other two. We need:\r\n",
        "\r\n",
        "*   **tensorflow == 1.14.0**\r\n",
        "*   **keras == 2.3.0**\r\n",
        "*   **keras-rl == 0.4.2**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDThCGZdM4-E"
      },
      "source": [
        "!apt-get install -y xvfb x11-utils > /dev/null 2>&1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ2E4VepMwuM"
      },
      "source": [
        "!pip install pyvirtualdisplay PyOpenGL PyOpenGL-accelerate gym-notebook-wrapper keras==2.3.0 tensorflow==1.14.0 keras-rl==0.4.2 gym matplotlib > /dev/null 2>&1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsLsKcmgb51p",
        "outputId": "a0575c50-8d7e-4fa7-ad30-b06774410878"
      },
      "source": [
        "import gym\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import gnwrapper\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Flatten\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "from rl.agents.dqn import DQNAgent\r\n",
        "from rl.policy import BoltzmannQPolicy\r\n",
        "from rl.memory import SequentialMemory"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2p9sC5TQpYx"
      },
      "source": [
        "# Global Variables\r\n",
        "\r\n",
        "This section define global variables that we use on notebook. I instance the paths where I save the model and the results and other paramenters for training and testing. So I define the env that I want to use for training an agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSDzNBxCQr7I"
      },
      "source": [
        "ENV_NAME = 'CartPole-v0'\r\n",
        "\r\n",
        "MODEL_PATH = './cartpole-v0'\r\n",
        "VIDEOS_PATH = MODEL_PATH + '/renders'\r\n",
        "MODEL_PATH = MODEL_PATH + '/model'\r\n",
        "\r\n",
        "TRAINING_STEPS = 50000\r\n",
        "TEST_EPISODES = 5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q3Myb3zLD6j"
      },
      "source": [
        "os.makedirs(MODEL_PATH, exist_ok=True)\r\n",
        "os.makedirs(VIDEOS_PATH, exist_ok=True)\r\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-JthJmyby1q"
      },
      "source": [
        "# Implementation\r\n",
        "\r\n",
        "In this section I implement different kinds of auxiliar functions that help me to build and train the model more easily.\r\n",
        "\r\n",
        "*    **build_model**: define and build the model of keras.\r\n",
        "*    **build_agent**: define and build the model of keras-rl from keras model.\r\n",
        "\r\n",
        "We can modify these funcitions if we want to use another keras neural network or another keras-rl reinforcement algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hWNH4DxaqoW"
      },
      "source": [
        "def build_model(input_shape: tuple, output_shape: tuple, verbose=False):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Flatten(input_shape=input_shape))\r\n",
        "  model.add(Dense(16))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(Dense(16))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(Dense(16))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(Dense(output_shape))\r\n",
        "  model.add(Activation('linear'))\r\n",
        "  if verbose: print(model.summary())\r\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv36alfsa7rt"
      },
      "source": [
        "def build_agent(model, nb_actions):\r\n",
        "  memory = SequentialMemory(limit=5000, window_length=1)\r\n",
        "  policy = BoltzmannQPolicy()\r\n",
        "  dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\r\n",
        "                target_model_update=1e-2, policy=policy)\r\n",
        "  dqn.compile(Adam(lr=1e-3), metrics=['mae'])\r\n",
        "  return dqn"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1XyeVmR9XNi"
      },
      "source": [
        "# Train & Test\r\n",
        "\r\n",
        "Here define the enviroment, train the agent and test it and display the results. We can see the training process printed on the console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbIu3l590OA7",
        "outputId": "ea49004b-8139-46b8-ada7-728fdd9da7b0"
      },
      "source": [
        "# [1] - Create the enviroment and wrap it into Monitor object for rendering\r\n",
        "#       results\r\n",
        "env = gnwrapper.Monitor(gym.make(ENV_NAME), directory=VIDEOS_PATH, force=True)\r\n",
        "env.seed(123)\r\n",
        "\r\n",
        "# [2] - Define variables that we need for defining the model and the RL\r\n",
        "#       algorithm\r\n",
        "nb_actions = env.action_space.n # Output size\r\n",
        "nb_observation = env.observation_space.shape # Input size\r\n",
        "nb_steps = TRAINING_STEPS # Max total steps for training \r\n",
        "nb_episodes = TEST_EPISODES # Episode for testing\r\n",
        "\r\n",
        "# [3] - Build the model and agent\r\n",
        "model = build_model(input_shape=(1,) + nb_observation, output_shape=nb_actions)\r\n",
        "agent = build_agent(model=model, nb_actions=nb_actions)\r\n",
        "\r\n",
        "# [4] - Train and test the agent into the enviroment selected\r\n",
        "train_history = agent.fit(env, nb_steps=nb_steps, visualize=True, verbose=2)\r\n",
        "test_history = agent.test(env, nb_episodes=nb_episodes, visualize=True)\r\n",
        "\r\n",
        "# [5] - Save the model \r\n",
        "agent.save_weights(MODEL_PATH + f'/dqn_{ENV_NAME}_weights.h5f', overwrite=True)\r\n",
        "\r\n",
        "# [6] - Display the results\r\n",
        "# env.display(reset=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 50000 steps ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    14/50000: episode: 1, duration: 1.537s, episode steps: 14, steps per second: 9, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.101 [-1.356, 0.774], loss: 0.528653, mae: 0.532742, mean_q: 0.000888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rl/memory.py:39: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    33/50000: episode: 2, duration: 0.404s, episode steps: 19, steps per second: 47, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.316 [0.000, 1.000], mean observation: 0.102 [-1.518, 2.509], loss: 0.424212, mae: 0.500293, mean_q: 0.119508\n",
            "    47/50000: episode: 3, duration: 0.156s, episode steps: 14, steps per second: 90, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.106 [-1.706, 2.672], loss: 0.269459, mae: 0.510112, mean_q: 0.464909\n",
            "    59/50000: episode: 4, duration: 0.085s, episode steps: 12, steps per second: 142, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.250 [0.000, 1.000], mean observation: 0.110 [-1.203, 2.021], loss: 0.190669, mae: 0.559129, mean_q: 0.785579\n",
            "    86/50000: episode: 5, duration: 0.177s, episode steps: 27, steps per second: 152, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.333 [0.000, 1.000], mean observation: 0.009 [-1.901, 2.623], loss: 0.139977, mae: 0.637061, mean_q: 1.033814\n",
            "    99/50000: episode: 6, duration: 0.090s, episode steps: 13, steps per second: 145, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.308 [0.000, 1.000], mean observation: 0.127 [-1.173, 2.011], loss: 0.083970, mae: 0.700024, mean_q: 1.339354\n",
            "   151/50000: episode: 7, duration: 0.333s, episode steps: 52, steps per second: 156, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.122 [-0.930, 1.404], loss: 0.056017, mae: 0.819707, mean_q: 1.695274\n",
            "   167/50000: episode: 8, duration: 0.106s, episode steps: 16, steps per second: 151, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.688 [0.000, 1.000], mean observation: -0.085 [-2.066, 1.178], loss: 0.034648, mae: 0.954405, mean_q: 1.957909\n",
            "   201/50000: episode: 9, duration: 0.564s, episode steps: 34, steps per second: 60, episode reward: 34.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.324 [0.000, 1.000], mean observation: 0.040 [-2.283, 3.295], loss: 0.050930, mae: 1.066116, mean_q: 2.124755\n",
            "   210/50000: episode: 10, duration: 0.139s, episode steps: 9, steps per second: 65, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.222 [0.000, 1.000], mean observation: 0.117 [-1.194, 1.954], loss: 0.065537, mae: 1.171004, mean_q: 2.358329\n",
            "   243/50000: episode: 11, duration: 0.207s, episode steps: 33, steps per second: 159, episode reward: 33.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.455 [0.000, 1.000], mean observation: 0.092 [-0.649, 1.723], loss: 0.071936, mae: 1.217537, mean_q: 2.484152\n",
            "   255/50000: episode: 12, duration: 0.078s, episode steps: 12, steps per second: 155, episode reward: 12.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.667 [0.000, 1.000], mean observation: -0.096 [-1.673, 1.025], loss: 0.050843, mae: 1.302271, mean_q: 2.676347\n",
            "   270/50000: episode: 13, duration: 0.097s, episode steps: 15, steps per second: 155, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.533 [0.000, 1.000], mean observation: -0.085 [-1.072, 0.634], loss: 0.101511, mae: 1.358361, mean_q: 2.734646\n",
            "   284/50000: episode: 14, duration: 0.093s, episode steps: 14, steps per second: 151, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.214 [0.000, 1.000], mean observation: 0.107 [-1.551, 2.538], loss: 0.065910, mae: 1.414844, mean_q: 2.850418\n",
            "   303/50000: episode: 15, duration: 0.130s, episode steps: 19, steps per second: 147, episode reward: 19.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: 0.064 [-0.989, 1.639], loss: 0.104395, mae: 1.496393, mean_q: 3.032813\n",
            "   328/50000: episode: 16, duration: 0.159s, episode steps: 25, steps per second: 157, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: -0.062 [-1.256, 0.611], loss: 0.098803, mae: 1.581695, mean_q: 3.226561\n",
            "   343/50000: episode: 17, duration: 0.094s, episode steps: 15, steps per second: 159, episode reward: 15.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.267 [0.000, 1.000], mean observation: 0.091 [-1.359, 2.312], loss: 0.114402, mae: 1.651458, mean_q: 3.368437\n",
            "   368/50000: episode: 18, duration: 0.156s, episode steps: 25, steps per second: 161, episode reward: 25.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.320 [0.000, 1.000], mean observation: 0.021 [-1.760, 2.555], loss: 0.142499, mae: 1.783092, mean_q: 3.536901\n",
            "   388/50000: episode: 19, duration: 0.126s, episode steps: 20, steps per second: 159, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.350 [0.000, 1.000], mean observation: 0.095 [-1.160, 2.097], loss: 0.140340, mae: 1.874721, mean_q: 3.698566\n",
            "   402/50000: episode: 20, duration: 0.093s, episode steps: 14, steps per second: 151, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.109 [-1.178, 2.081], loss: 0.145755, mae: 1.923989, mean_q: 3.854893\n",
            "   430/50000: episode: 21, duration: 0.179s, episode steps: 28, steps per second: 156, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.357 [0.000, 1.000], mean observation: 0.082 [-1.548, 2.593], loss: 0.151626, mae: 2.050332, mean_q: 4.078876\n",
            "   447/50000: episode: 22, duration: 0.117s, episode steps: 17, steps per second: 145, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: 0.084 [-0.989, 1.521], loss: 0.142869, mae: 2.124684, mean_q: 4.226532\n",
            "   467/50000: episode: 23, duration: 0.128s, episode steps: 20, steps per second: 156, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.400 [0.000, 1.000], mean observation: 0.095 [-0.953, 1.814], loss: 0.140604, mae: 2.222202, mean_q: 4.413548\n",
            "   498/50000: episode: 24, duration: 0.209s, episode steps: 31, steps per second: 148, episode reward: 31.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.516 [0.000, 1.000], mean observation: 0.127 [-0.443, 1.046], loss: 0.238283, mae: 2.328769, mean_q: 4.523416\n",
            "   516/50000: episode: 25, duration: 0.117s, episode steps: 18, steps per second: 154, episode reward: 18.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.278 [0.000, 1.000], mean observation: 0.060 [-1.583, 2.548], loss: 0.164528, mae: 2.458981, mean_q: 4.775838\n",
            "   533/50000: episode: 26, duration: 0.117s, episode steps: 17, steps per second: 145, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: 0.098 [-0.394, 1.078], loss: 0.205458, mae: 2.528573, mean_q: 4.882832\n",
            "   549/50000: episode: 27, duration: 0.104s, episode steps: 16, steps per second: 154, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.438 [0.000, 1.000], mean observation: 0.064 [-0.796, 1.254], loss: 0.206265, mae: 2.563460, mean_q: 5.000647\n",
            "   565/50000: episode: 28, duration: 0.328s, episode steps: 16, steps per second: 49, episode reward: 16.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.105 [-1.420, 0.927], loss: 0.187376, mae: 2.646587, mean_q: 5.217779\n",
            "   578/50000: episode: 29, duration: 0.129s, episode steps: 13, steps per second: 101, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.385 [0.000, 1.000], mean observation: 0.125 [-0.933, 1.548], loss: 0.231629, mae: 2.715844, mean_q: 5.243472\n",
            "   616/50000: episode: 30, duration: 0.232s, episode steps: 38, steps per second: 164, episode reward: 38.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.024 [-1.189, 0.825], loss: 0.208826, mae: 2.804669, mean_q: 5.422894\n",
            "   645/50000: episode: 31, duration: 0.176s, episode steps: 29, steps per second: 165, episode reward: 29.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.586 [0.000, 1.000], mean observation: -0.078 [-1.916, 0.962], loss: 0.278827, mae: 2.916544, mean_q: 5.617417\n",
            "   654/50000: episode: 32, duration: 0.061s, episode steps: 9, steps per second: 147, episode reward: 9.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 0.141 [-1.807, 2.880], loss: 0.184451, mae: 2.962690, mean_q: 5.721212\n",
            "   668/50000: episode: 33, duration: 0.087s, episode steps: 14, steps per second: 161, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.286 [0.000, 1.000], mean observation: 0.100 [-1.349, 2.201], loss: 0.234088, mae: 3.053427, mean_q: 5.870960\n",
            "   707/50000: episode: 34, duration: 0.240s, episode steps: 39, steps per second: 163, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.117 [-0.539, 1.148], loss: 0.201436, mae: 3.129255, mean_q: 6.047463\n",
            "   731/50000: episode: 35, duration: 0.157s, episode steps: 24, steps per second: 152, episode reward: 24.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.542 [0.000, 1.000], mean observation: -0.055 [-1.411, 0.952], loss: 0.221770, mae: 3.202103, mean_q: 6.117840\n",
            "   742/50000: episode: 36, duration: 0.073s, episode steps: 11, steps per second: 150, episode reward: 11.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.818 [0.000, 1.000], mean observation: -0.131 [-2.300, 1.353], loss: 0.234525, mae: 3.316323, mean_q: 6.369887\n",
            "   765/50000: episode: 37, duration: 0.143s, episode steps: 23, steps per second: 161, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: 0.061 [-0.962, 1.524], loss: 0.207483, mae: 3.337831, mean_q: 6.395337\n",
            "   778/50000: episode: 38, duration: 0.088s, episode steps: 13, steps per second: 148, episode reward: 13.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.615 [0.000, 1.000], mean observation: -0.097 [-1.753, 1.191], loss: 0.154327, mae: 3.403966, mean_q: 6.535429\n",
            "   810/50000: episode: 39, duration: 0.208s, episode steps: 32, steps per second: 154, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.562 [0.000, 1.000], mean observation: -0.043 [-1.486, 0.866], loss: 0.298425, mae: 3.465133, mean_q: 6.632620\n",
            "   827/50000: episode: 40, duration: 0.107s, episode steps: 17, steps per second: 159, episode reward: 17.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.529 [0.000, 1.000], mean observation: 0.090 [-0.793, 1.173], loss: 0.275376, mae: 3.537111, mean_q: 6.793437\n",
            "   888/50000: episode: 41, duration: 0.377s, episode steps: 61, steps per second: 162, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.443 [0.000, 1.000], mean observation: -0.067 [-1.895, 1.798], loss: 0.275535, mae: 3.708319, mean_q: 7.147484\n",
            "   909/50000: episode: 42, duration: 0.131s, episode steps: 21, steps per second: 160, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.429 [0.000, 1.000], mean observation: 0.073 [-0.656, 1.411], loss: 0.362313, mae: 3.855875, mean_q: 7.424673\n",
            "   923/50000: episode: 43, duration: 0.092s, episode steps: 14, steps per second: 152, episode reward: 14.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.571 [0.000, 1.000], mean observation: -0.060 [-1.688, 1.208], loss: 0.438963, mae: 3.888414, mean_q: 7.426098\n",
            "   951/50000: episode: 44, duration: 0.179s, episode steps: 28, steps per second: 156, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.090 [-0.545, 1.034], loss: 0.344836, mae: 3.997277, mean_q: 7.726615\n",
            "   974/50000: episode: 45, duration: 0.146s, episode steps: 23, steps per second: 157, episode reward: 23.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: -0.070 [-1.153, 0.820], loss: 0.338213, mae: 4.104925, mean_q: 7.964079\n",
            "   994/50000: episode: 46, duration: 0.125s, episode steps: 20, steps per second: 160, episode reward: 20.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.121 [-0.375, 1.092], loss: 0.491720, mae: 4.119235, mean_q: 7.898211\n",
            "  1026/50000: episode: 47, duration: 0.203s, episode steps: 32, steps per second: 158, episode reward: 32.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.531 [0.000, 1.000], mean observation: -0.041 [-1.209, 0.457], loss: 0.397622, mae: 4.271637, mean_q: 8.252842\n",
            "  1073/50000: episode: 48, duration: 0.300s, episode steps: 47, steps per second: 157, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.447 [0.000, 1.000], mean observation: -0.003 [-1.201, 1.713], loss: 0.333512, mae: 4.451171, mean_q: 8.668664\n",
            "  1112/50000: episode: 49, duration: 0.243s, episode steps: 39, steps per second: 161, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: -0.023 [-1.092, 0.894], loss: 0.537976, mae: 4.567003, mean_q: 8.856699\n",
            "  1179/50000: episode: 50, duration: 0.411s, episode steps: 67, steps per second: 163, episode reward: 67.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.478 [0.000, 1.000], mean observation: -0.086 [-1.451, 1.063], loss: 0.434093, mae: 4.791798, mean_q: 9.315288\n",
            "  1264/50000: episode: 51, duration: 0.524s, episode steps: 85, steps per second: 162, episode reward: 85.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: -0.129 [-1.598, 0.974], loss: 0.419920, mae: 5.083742, mean_q: 9.953713\n",
            "  1291/50000: episode: 52, duration: 0.172s, episode steps: 27, steps per second: 157, episode reward: 27.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.444 [0.000, 1.000], mean observation: -0.095 [-1.066, 0.560], loss: 0.535450, mae: 5.312171, mean_q: 10.343795\n",
            "  1312/50000: episode: 53, duration: 0.151s, episode steps: 21, steps per second: 139, episode reward: 21.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.045 [-1.207, 1.652], loss: 0.444654, mae: 5.283057, mean_q: 10.312900\n",
            "  1338/50000: episode: 54, duration: 0.157s, episode steps: 26, steps per second: 165, episode reward: 26.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.080 [-0.593, 0.936], loss: 0.450901, mae: 5.482816, mean_q: 10.762156\n",
            "  1424/50000: episode: 55, duration: 0.520s, episode steps: 86, steps per second: 165, episode reward: 86.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.045 [-1.087, 1.192], loss: 0.673672, mae: 5.704774, mean_q: 11.096157\n",
            "  1485/50000: episode: 56, duration: 0.359s, episode steps: 61, steps per second: 170, episode reward: 61.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.443 [0.000, 1.000], mean observation: -0.320 [-1.690, 0.765], loss: 0.625360, mae: 5.943567, mean_q: 11.564642\n",
            "  1598/50000: episode: 57, duration: 0.655s, episode steps: 113, steps per second: 172, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.496 [0.000, 1.000], mean observation: -0.182 [-1.723, 0.850], loss: 0.658099, mae: 6.245667, mean_q: 12.214803\n",
            "  1640/50000: episode: 58, duration: 0.249s, episode steps: 42, steps per second: 168, episode reward: 42.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.524 [0.000, 1.000], mean observation: 0.124 [-0.582, 1.109], loss: 0.741460, mae: 6.483773, mean_q: 12.704576\n",
            "  1668/50000: episode: 59, duration: 0.165s, episode steps: 28, steps per second: 169, episode reward: 28.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.066 [-0.821, 1.280], loss: 0.805911, mae: 6.626819, mean_q: 12.887355\n",
            "  1722/50000: episode: 60, duration: 0.319s, episode steps: 54, steps per second: 169, episode reward: 54.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.024 [-1.024, 0.908], loss: 0.639182, mae: 6.748441, mean_q: 13.283348\n",
            "  1802/50000: episode: 61, duration: 0.469s, episode steps: 80, steps per second: 170, episode reward: 80.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.080 [-1.283, 1.599], loss: 0.711685, mae: 7.003357, mean_q: 13.819702\n",
            "  1875/50000: episode: 62, duration: 0.433s, episode steps: 73, steps per second: 169, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: -0.246 [-2.008, 1.031], loss: 0.549921, mae: 7.266313, mean_q: 14.389854\n",
            "  2067/50000: episode: 63, duration: 1.100s, episode steps: 192, steps per second: 174, episode reward: 192.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.131 [-1.449, 1.725], loss: 0.689361, mae: 7.667927, mean_q: 15.311236\n",
            "  2216/50000: episode: 64, duration: 0.864s, episode steps: 149, steps per second: 172, episode reward: 149.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.224 [-1.810, 1.025], loss: 0.615222, mae: 8.256060, mean_q: 16.642357\n",
            "  2316/50000: episode: 65, duration: 1.543s, episode steps: 100, steps per second: 65, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.173 [-1.570, 0.843], loss: 0.801913, mae: 8.742681, mean_q: 17.703957\n",
            "  2509/50000: episode: 66, duration: 1.167s, episode steps: 193, steps per second: 165, episode reward: 193.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.175 [-1.829, 1.438], loss: 0.793125, mae: 9.435904, mean_q: 19.107374\n",
            "  2709/50000: episode: 67, duration: 1.162s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.053 [-1.469, 1.335], loss: 1.012348, mae: 10.308928, mean_q: 20.922779\n",
            "  2858/50000: episode: 68, duration: 0.853s, episode steps: 149, steps per second: 175, episode reward: 149.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.306 [-2.186, 1.024], loss: 1.085730, mae: 11.067391, mean_q: 22.494169\n",
            "  2982/50000: episode: 69, duration: 0.724s, episode steps: 124, steps per second: 171, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.302 [-1.817, 1.286], loss: 1.233056, mae: 11.677484, mean_q: 23.801598\n",
            "  3182/50000: episode: 70, duration: 1.153s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.480 [0.000, 1.000], mean observation: -0.163 [-1.648, 1.296], loss: 1.672534, mae: 12.456621, mean_q: 25.316130\n",
            "  3347/50000: episode: 71, duration: 0.931s, episode steps: 165, steps per second: 177, episode reward: 165.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.509 [0.000, 1.000], mean observation: 0.140 [-1.317, 1.289], loss: 1.486090, mae: 13.220177, mean_q: 26.909121\n",
            "  3521/50000: episode: 72, duration: 0.998s, episode steps: 174, steps per second: 174, episode reward: 174.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.256 [-1.800, 0.900], loss: 2.003862, mae: 13.939787, mean_q: 28.299120\n",
            "  3633/50000: episode: 73, duration: 0.657s, episode steps: 112, steps per second: 170, episode reward: 112.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.365 [-1.717, 0.926], loss: 1.938673, mae: 14.379966, mean_q: 29.303497\n",
            "  3783/50000: episode: 74, duration: 0.874s, episode steps: 150, steps per second: 172, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: 0.169 [-0.828, 0.957], loss: 2.078352, mae: 15.121025, mean_q: 30.760899\n",
            "  3934/50000: episode: 75, duration: 0.880s, episode steps: 151, steps per second: 172, episode reward: 151.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.361 [-2.175, 1.124], loss: 1.986670, mae: 15.669438, mean_q: 31.935062\n",
            "  4134/50000: episode: 76, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: 0.110 [-1.022, 1.177], loss: 1.876437, mae: 16.415882, mean_q: 33.464596\n",
            "  4282/50000: episode: 77, duration: 0.862s, episode steps: 148, steps per second: 172, episode reward: 148.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.268 [-1.800, 1.092], loss: 2.559954, mae: 17.037100, mean_q: 34.538582\n",
            "  4382/50000: episode: 78, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 100.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.188 [-1.100, 1.151], loss: 1.978297, mae: 17.598272, mean_q: 35.740963\n",
            "  4544/50000: episode: 79, duration: 0.940s, episode steps: 162, steps per second: 172, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.371 [-2.704, 1.004], loss: 2.531910, mae: 17.987476, mean_q: 36.562378\n",
            "  4690/50000: episode: 80, duration: 0.870s, episode steps: 146, steps per second: 168, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.320 [-1.974, 0.917], loss: 2.840604, mae: 18.502886, mean_q: 37.572567\n",
            "  4889/50000: episode: 81, duration: 1.163s, episode steps: 199, steps per second: 171, episode reward: 199.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.282 [-2.362, 0.988], loss: 2.139402, mae: 19.192026, mean_q: 39.157753\n",
            "  5060/50000: episode: 82, duration: 0.996s, episode steps: 171, steps per second: 172, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.359 [-2.525, 0.990], loss: 2.054078, mae: 19.866608, mean_q: 40.525875\n",
            "  5242/50000: episode: 83, duration: 1.058s, episode steps: 182, steps per second: 172, episode reward: 182.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.332 [-2.764, 0.960], loss: 2.386968, mae: 20.419966, mean_q: 41.542095\n",
            "  5442/50000: episode: 84, duration: 1.167s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.281 [-2.529, 0.977], loss: 2.450250, mae: 21.135408, mean_q: 42.983379\n",
            "  5625/50000: episode: 85, duration: 1.053s, episode steps: 183, steps per second: 174, episode reward: 183.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.276 [-2.023, 0.936], loss: 2.518665, mae: 21.828011, mean_q: 44.315109\n",
            "  5798/50000: episode: 86, duration: 1.021s, episode steps: 173, steps per second: 169, episode reward: 173.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.296 [-2.193, 0.918], loss: 2.198333, mae: 22.337397, mean_q: 45.380722\n",
            "  5974/50000: episode: 87, duration: 1.006s, episode steps: 176, steps per second: 175, episode reward: 176.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.313 [-2.350, 0.841], loss: 1.894380, mae: 22.904972, mean_q: 46.464588\n",
            "  6145/50000: episode: 88, duration: 0.984s, episode steps: 171, steps per second: 174, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.365 [-2.592, 0.908], loss: 2.055631, mae: 23.228910, mean_q: 47.073677\n",
            "  6345/50000: episode: 89, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.180 [-2.055, 0.981], loss: 1.519072, mae: 23.679899, mean_q: 48.004501\n",
            "  6484/50000: episode: 90, duration: 0.796s, episode steps: 139, steps per second: 175, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.394 [-2.374, 1.087], loss: 1.291573, mae: 24.081161, mean_q: 48.689152\n",
            "  6620/50000: episode: 91, duration: 0.780s, episode steps: 136, steps per second: 174, episode reward: 136.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.342 [-1.979, 1.060], loss: 1.317568, mae: 24.248926, mean_q: 48.959789\n",
            "  6773/50000: episode: 92, duration: 0.897s, episode steps: 153, steps per second: 171, episode reward: 153.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.325 [-2.233, 0.911], loss: 0.692384, mae: 24.725824, mean_q: 50.001728\n",
            "  6912/50000: episode: 93, duration: 0.820s, episode steps: 139, steps per second: 170, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.338 [-2.023, 1.449], loss: 1.211226, mae: 24.972628, mean_q: 50.351738\n",
            "  7051/50000: episode: 94, duration: 0.812s, episode steps: 139, steps per second: 171, episode reward: 139.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.436 [-2.582, 0.736], loss: 0.887800, mae: 24.988615, mean_q: 50.444897\n",
            "  7241/50000: episode: 95, duration: 1.106s, episode steps: 190, steps per second: 172, episode reward: 190.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.300 [-2.361, 1.005], loss: 0.937755, mae: 25.159210, mean_q: 50.703598\n",
            "  7401/50000: episode: 96, duration: 0.925s, episode steps: 160, steps per second: 173, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.306 [-2.171, 0.780], loss: 1.003765, mae: 25.461338, mean_q: 51.396717\n",
            "  7536/50000: episode: 97, duration: 0.796s, episode steps: 135, steps per second: 170, episode reward: 135.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.459 [0.000, 1.000], mean observation: -0.450 [-2.424, 0.843], loss: 0.717003, mae: 25.512903, mean_q: 51.490887\n",
            "  7712/50000: episode: 98, duration: 1.020s, episode steps: 176, steps per second: 173, episode reward: 176.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.345 [-2.542, 1.179], loss: 0.457424, mae: 25.700157, mean_q: 51.850155\n",
            "  7862/50000: episode: 99, duration: 0.887s, episode steps: 150, steps per second: 169, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.386 [-2.975, 1.263], loss: 0.394561, mae: 25.891232, mean_q: 52.213066\n",
            "  8014/50000: episode: 100, duration: 0.889s, episode steps: 152, steps per second: 171, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.387 [-3.009, 1.251], loss: 0.320461, mae: 26.058052, mean_q: 52.533203\n",
            "  8146/50000: episode: 101, duration: 0.797s, episode steps: 132, steps per second: 166, episode reward: 132.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.368 [-2.214, 0.965], loss: 0.597193, mae: 26.308290, mean_q: 53.018303\n",
            "  8306/50000: episode: 102, duration: 0.929s, episode steps: 160, steps per second: 172, episode reward: 160.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.481 [0.000, 1.000], mean observation: -0.290 [-2.244, 1.108], loss: 0.372055, mae: 26.239887, mean_q: 52.852486\n",
            "  8479/50000: episode: 103, duration: 1.000s, episode steps: 173, steps per second: 173, episode reward: 173.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.339 [-2.593, 1.351], loss: 0.483001, mae: 26.171385, mean_q: 52.749943\n",
            "  8640/50000: episode: 104, duration: 0.923s, episode steps: 161, steps per second: 174, episode reward: 161.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.453 [0.000, 1.000], mean observation: -0.384 [-2.752, 1.318], loss: 0.352968, mae: 26.959051, mean_q: 54.359921\n",
            "  8803/50000: episode: 105, duration: 0.951s, episode steps: 163, steps per second: 171, episode reward: 163.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.366 [-2.988, 1.352], loss: 0.621175, mae: 26.543997, mean_q: 53.471649\n",
            "  8839/50000: episode: 106, duration: 0.220s, episode steps: 36, steps per second: 164, episode reward: 36.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.051 [-1.346, 1.465], loss: 0.610183, mae: 27.110991, mean_q: 54.616531\n",
            "  9039/50000: episode: 107, duration: 1.171s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.157 [-2.410, 1.371], loss: 0.951804, mae: 27.293177, mean_q: 54.926300\n",
            "  9239/50000: episode: 108, duration: 1.174s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.044 [-1.327, 1.183], loss: 0.786988, mae: 27.454580, mean_q: 55.310272\n",
            "  9433/50000: episode: 109, duration: 1.141s, episode steps: 194, steps per second: 170, episode reward: 194.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.318 [-2.724, 1.380], loss: 1.290759, mae: 28.263586, mean_q: 56.879932\n",
            "  9607/50000: episode: 110, duration: 1.012s, episode steps: 174, steps per second: 172, episode reward: 174.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.357 [-2.430, 1.127], loss: 1.332490, mae: 28.551331, mean_q: 57.401512\n",
            "  9726/50000: episode: 111, duration: 0.695s, episode steps: 119, steps per second: 171, episode reward: 119.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.312 [-1.672, 1.033], loss: 2.641006, mae: 28.435347, mean_q: 57.051842\n",
            "  9869/50000: episode: 112, duration: 0.848s, episode steps: 143, steps per second: 169, episode reward: 143.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.257 [-1.670, 1.348], loss: 1.752483, mae: 28.897242, mean_q: 57.973244\n",
            " 10069/50000: episode: 113, duration: 1.162s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.155 [-1.809, 1.151], loss: 0.557742, mae: 28.792282, mean_q: 57.900597\n",
            " 10215/50000: episode: 114, duration: 0.843s, episode steps: 146, steps per second: 173, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.400 [-2.450, 1.198], loss: 0.916987, mae: 28.864183, mean_q: 58.048786\n",
            " 10379/50000: episode: 115, duration: 0.943s, episode steps: 164, steps per second: 174, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.451 [0.000, 1.000], mean observation: -0.376 [-2.982, 1.284], loss: 1.630283, mae: 28.922714, mean_q: 58.145096\n",
            " 10579/50000: episode: 116, duration: 1.176s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.032 [-1.754, 1.672], loss: 0.931592, mae: 29.611057, mean_q: 59.538746\n",
            " 10700/50000: episode: 117, duration: 0.708s, episode steps: 121, steps per second: 171, episode reward: 121.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.463 [0.000, 1.000], mean observation: -0.307 [-1.708, 1.733], loss: 2.058143, mae: 29.494392, mean_q: 59.274464\n",
            " 10850/50000: episode: 118, duration: 0.877s, episode steps: 150, steps per second: 171, episode reward: 150.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.373 [-2.101, 1.470], loss: 1.218909, mae: 29.557318, mean_q: 59.441563\n",
            " 10974/50000: episode: 119, duration: 0.726s, episode steps: 124, steps per second: 171, episode reward: 124.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.460 [0.000, 1.000], mean observation: -0.445 [-2.158, 1.052], loss: 3.378574, mae: 29.772306, mean_q: 59.737968\n",
            " 11145/50000: episode: 120, duration: 1.016s, episode steps: 171, steps per second: 168, episode reward: 171.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.462 [0.000, 1.000], mean observation: -0.374 [-2.518, 1.201], loss: 3.155603, mae: 29.751097, mean_q: 59.680794\n",
            " 11271/50000: episode: 121, duration: 0.731s, episode steps: 126, steps per second: 172, episode reward: 126.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.169 [-2.045, 1.811], loss: 4.723660, mae: 29.649982, mean_q: 59.385166\n",
            " 11327/50000: episode: 122, duration: 0.330s, episode steps: 56, steps per second: 170, episode reward: 56.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.482 [0.000, 1.000], mean observation: 0.033 [-1.742, 2.060], loss: 3.614851, mae: 29.843019, mean_q: 59.847076\n",
            " 11479/50000: episode: 123, duration: 0.896s, episode steps: 152, steps per second: 170, episode reward: 152.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.454 [0.000, 1.000], mean observation: -0.417 [-2.608, 0.847], loss: 3.545432, mae: 29.957468, mean_q: 60.163425\n",
            " 11654/50000: episode: 124, duration: 1.021s, episode steps: 175, steps per second: 171, episode reward: 175.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.361 [-2.581, 1.184], loss: 2.499888, mae: 29.916183, mean_q: 60.187454\n",
            " 11854/50000: episode: 125, duration: 1.157s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.060 [-1.606, 1.542], loss: 1.759450, mae: 30.186270, mean_q: 60.840946\n",
            " 11995/50000: episode: 126, duration: 2.105s, episode steps: 141, steps per second: 67, episode reward: 141.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.461 [0.000, 1.000], mean observation: -0.437 [-2.432, 0.844], loss: 3.172967, mae: 30.525438, mean_q: 61.493599\n",
            " 12195/50000: episode: 127, duration: 1.288s, episode steps: 200, steps per second: 155, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.196 [-1.813, 1.563], loss: 2.697466, mae: 30.834576, mean_q: 62.102371\n",
            " 12395/50000: episode: 128, duration: 1.170s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.013 [-1.494, 1.206], loss: 4.142931, mae: 30.986467, mean_q: 62.356903\n",
            " 12595/50000: episode: 129, duration: 1.153s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.223 [-1.882, 1.217], loss: 4.328033, mae: 31.611059, mean_q: 63.600704\n",
            " 12795/50000: episode: 130, duration: 1.175s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.259 [-2.230, 1.520], loss: 3.155980, mae: 31.932930, mean_q: 64.301781\n",
            " 12963/50000: episode: 131, duration: 0.980s, episode steps: 168, steps per second: 171, episode reward: 168.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.378 [-2.421, 1.024], loss: 4.000532, mae: 32.162796, mean_q: 64.690697\n",
            " 13149/50000: episode: 132, duration: 1.076s, episode steps: 186, steps per second: 173, episode reward: 186.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.468 [0.000, 1.000], mean observation: -0.360 [-2.423, 0.829], loss: 2.227043, mae: 32.311081, mean_q: 65.111496\n",
            " 13332/50000: episode: 133, duration: 1.063s, episode steps: 183, steps per second: 172, episode reward: 183.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.464 [0.000, 1.000], mean observation: -0.358 [-2.426, 0.942], loss: 1.445089, mae: 32.504097, mean_q: 65.496208\n",
            " 13516/50000: episode: 134, duration: 1.075s, episode steps: 184, steps per second: 171, episode reward: 184.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.357 [-2.406, 1.256], loss: 3.424685, mae: 32.422733, mean_q: 65.255646\n",
            " 13712/50000: episode: 135, duration: 1.123s, episode steps: 196, steps per second: 175, episode reward: 196.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.469 [0.000, 1.000], mean observation: -0.332 [-2.411, 1.143], loss: 2.113492, mae: 32.511555, mean_q: 65.470558\n",
            " 13912/50000: episode: 136, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.188 [-1.536, 0.998], loss: 4.281675, mae: 33.101933, mean_q: 66.515335\n",
            " 14112/50000: episode: 137, duration: 1.167s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.034 [-1.258, 1.081], loss: 4.147777, mae: 33.333111, mean_q: 67.040482\n",
            " 14284/50000: episode: 138, duration: 1.001s, episode steps: 172, steps per second: 172, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.471 [0.000, 1.000], mean observation: -0.382 [-2.419, 1.312], loss: 5.143167, mae: 33.319145, mean_q: 66.878052\n",
            " 14468/50000: episode: 139, duration: 1.108s, episode steps: 184, steps per second: 166, episode reward: 184.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.473 [0.000, 1.000], mean observation: -0.352 [-2.420, 0.740], loss: 3.928353, mae: 33.091164, mean_q: 66.562492\n",
            " 14612/50000: episode: 140, duration: 0.838s, episode steps: 144, steps per second: 172, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.458 [0.000, 1.000], mean observation: -0.434 [-2.412, 1.231], loss: 5.468222, mae: 33.067142, mean_q: 66.317398\n",
            " 14812/50000: episode: 141, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.079 [-1.205, 0.943], loss: 1.617538, mae: 33.223862, mean_q: 66.886093\n",
            " 15012/50000: episode: 142, duration: 1.162s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.200 [-1.474, 1.140], loss: 3.561240, mae: 33.717785, mean_q: 67.766556\n",
            " 15212/50000: episode: 143, duration: 1.153s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.045 [-1.190, 1.246], loss: 2.177820, mae: 33.846226, mean_q: 68.149841\n",
            " 15376/50000: episode: 144, duration: 0.988s, episode steps: 164, steps per second: 166, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.470 [0.000, 1.000], mean observation: -0.400 [-2.332, 0.970], loss: 7.230843, mae: 34.414776, mean_q: 69.013443\n",
            " 15576/50000: episode: 145, duration: 1.151s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.475 [0.000, 1.000], mean observation: -0.245 [-2.006, 1.208], loss: 4.891310, mae: 33.963455, mean_q: 68.081406\n",
            " 15748/50000: episode: 146, duration: 0.986s, episode steps: 172, steps per second: 174, episode reward: 172.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.465 [0.000, 1.000], mean observation: -0.386 [-2.424, 1.065], loss: 4.713334, mae: 34.025173, mean_q: 68.237228\n",
            " 15923/50000: episode: 147, duration: 1.031s, episode steps: 175, steps per second: 170, episode reward: 175.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.328 [-1.996, 1.411], loss: 3.887158, mae: 34.202679, mean_q: 68.560783\n",
            " 16123/50000: episode: 148, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.031 [-1.308, 1.343], loss: 5.156431, mae: 34.227467, mean_q: 68.586220\n",
            " 16320/50000: episode: 149, duration: 1.142s, episode steps: 197, steps per second: 173, episode reward: 197.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.472 [0.000, 1.000], mean observation: -0.333 [-2.408, 1.115], loss: 5.550835, mae: 34.935345, mean_q: 69.965965\n",
            " 16496/50000: episode: 150, duration: 1.003s, episode steps: 176, steps per second: 175, episode reward: 176.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.477 [0.000, 1.000], mean observation: -0.371 [-2.423, 1.462], loss: 5.504820, mae: 34.688431, mean_q: 69.352180\n",
            " 16696/50000: episode: 151, duration: 1.150s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.016 [-1.233, 1.440], loss: 4.906590, mae: 34.989208, mean_q: 70.171509\n",
            " 16870/50000: episode: 152, duration: 1.004s, episode steps: 174, steps per second: 173, episode reward: 174.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.466 [0.000, 1.000], mean observation: -0.392 [-2.419, 1.557], loss: 4.023119, mae: 35.171219, mean_q: 70.487663\n",
            " 17070/50000: episode: 153, duration: 1.168s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.263 [-2.425, 1.523], loss: 3.699390, mae: 35.141495, mean_q: 70.435402\n",
            " 17270/50000: episode: 154, duration: 1.155s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: -0.174 [-1.534, 1.195], loss: 5.641170, mae: 35.336559, mean_q: 70.640450\n",
            " 17470/50000: episode: 155, duration: 1.147s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.050 [-1.710, 1.447], loss: 3.846750, mae: 35.210747, mean_q: 70.495872\n",
            " 17638/50000: episode: 156, duration: 0.977s, episode steps: 168, steps per second: 172, episode reward: 168.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: -0.236 [-1.531, 1.235], loss: 4.728056, mae: 35.339825, mean_q: 70.775970\n",
            " 17838/50000: episode: 157, duration: 1.166s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.097 [-1.228, 1.127], loss: 3.014078, mae: 35.559574, mean_q: 71.340538\n",
            " 17996/50000: episode: 158, duration: 0.907s, episode steps: 158, steps per second: 174, episode reward: 158.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.054 [-1.373, 1.244], loss: 5.266273, mae: 35.955929, mean_q: 71.929413\n",
            " 18142/50000: episode: 159, duration: 0.863s, episode steps: 146, steps per second: 169, episode reward: 146.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.507 [0.000, 1.000], mean observation: 0.116 [-0.975, 1.007], loss: 5.275374, mae: 36.141228, mean_q: 72.343842\n",
            " 18298/50000: episode: 160, duration: 0.909s, episode steps: 156, steps per second: 172, episode reward: 156.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: -0.166 [-1.707, 1.284], loss: 3.307543, mae: 36.624504, mean_q: 73.369606\n",
            " 18436/50000: episode: 161, duration: 0.793s, episode steps: 138, steps per second: 174, episode reward: 138.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.148 [-1.380, 1.577], loss: 7.069458, mae: 36.548058, mean_q: 73.057053\n",
            " 18541/50000: episode: 162, duration: 0.614s, episode steps: 105, steps per second: 171, episode reward: 105.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.164 [-1.196, 1.349], loss: 6.260124, mae: 36.691689, mean_q: 73.121620\n",
            " 18741/50000: episode: 163, duration: 1.155s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.083 [-1.015, 1.475], loss: 5.492512, mae: 36.718590, mean_q: 73.274811\n",
            " 18850/50000: episode: 164, duration: 0.634s, episode steps: 109, steps per second: 172, episode reward: 109.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.158 [-1.154, 1.490], loss: 6.446668, mae: 37.022552, mean_q: 73.951286\n",
            " 19050/50000: episode: 165, duration: 1.143s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.129 [-1.546, 1.468], loss: 5.702514, mae: 36.472626, mean_q: 72.853607\n",
            " 19213/50000: episode: 166, duration: 0.952s, episode steps: 163, steps per second: 171, episode reward: 163.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.497 [0.000, 1.000], mean observation: 0.139 [-1.206, 1.874], loss: 6.947854, mae: 36.352486, mean_q: 72.528435\n",
            " 19413/50000: episode: 167, duration: 1.149s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.068 [-1.494, 1.352], loss: 3.305644, mae: 36.479286, mean_q: 72.983177\n",
            " 19609/50000: episode: 168, duration: 1.123s, episode steps: 196, steps per second: 175, episode reward: 196.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.127 [-2.058, 2.186], loss: 5.519231, mae: 37.035080, mean_q: 74.010277\n",
            " 19809/50000: episode: 169, duration: 1.161s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.120 [-2.009, 1.991], loss: 3.808008, mae: 37.196774, mean_q: 74.404739\n",
            " 20009/50000: episode: 170, duration: 1.166s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.038 [-1.253, 1.155], loss: 5.181459, mae: 37.537994, mean_q: 75.037796\n",
            " 20066/50000: episode: 171, duration: 0.338s, episode steps: 57, steps per second: 169, episode reward: 57.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.474 [0.000, 1.000], mean observation: -0.032 [-1.383, 1.603], loss: 5.796887, mae: 38.248707, mean_q: 76.539032\n",
            " 20266/50000: episode: 172, duration: 1.157s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.045 [-1.728, 1.326], loss: 6.851377, mae: 37.932770, mean_q: 75.773819\n",
            " 20466/50000: episode: 173, duration: 1.171s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.186 [-1.521, 1.630], loss: 5.899750, mae: 38.159443, mean_q: 76.409821\n",
            " 20666/50000: episode: 174, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.098 [-1.664, 1.299], loss: 9.885403, mae: 38.756241, mean_q: 77.499809\n",
            " 20866/50000: episode: 175, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.077 [-1.089, 1.036], loss: 8.210624, mae: 39.199177, mean_q: 78.464851\n",
            " 21066/50000: episode: 176, duration: 1.145s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.096 [-0.965, 0.819], loss: 8.119187, mae: 39.205795, mean_q: 78.675987\n",
            " 21266/50000: episode: 177, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.028 [-0.812, 0.738], loss: 6.648365, mae: 39.695877, mean_q: 79.755898\n",
            " 21466/50000: episode: 178, duration: 1.159s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.000 [-0.854, 0.808], loss: 5.634687, mae: 40.470600, mean_q: 81.383064\n",
            " 21666/50000: episode: 179, duration: 1.189s, episode steps: 200, steps per second: 168, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.036 [-1.140, 1.052], loss: 11.070155, mae: 41.123150, mean_q: 82.561287\n",
            " 21866/50000: episode: 180, duration: 1.156s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.121 [-1.448, 1.104], loss: 11.054010, mae: 41.622459, mean_q: 83.563255\n",
            " 22066/50000: episode: 181, duration: 1.153s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.064 [-1.351, 1.240], loss: 11.164909, mae: 42.065163, mean_q: 84.447540\n",
            " 22266/50000: episode: 182, duration: 1.140s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.086 [-1.259, 1.303], loss: 13.146963, mae: 42.331665, mean_q: 84.921494\n",
            " 22466/50000: episode: 183, duration: 1.191s, episode steps: 200, steps per second: 168, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.003 [-1.212, 0.947], loss: 12.282746, mae: 42.671455, mean_q: 85.609032\n",
            " 22666/50000: episode: 184, duration: 1.194s, episode steps: 200, steps per second: 168, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.061 [-1.122, 0.769], loss: 8.588070, mae: 42.807041, mean_q: 86.153625\n",
            " 22866/50000: episode: 185, duration: 1.168s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.015 [-0.810, 0.828], loss: 6.051302, mae: 43.581532, mean_q: 87.668831\n",
            " 23066/50000: episode: 186, duration: 1.168s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.006 [-1.190, 1.158], loss: 13.397517, mae: 43.881012, mean_q: 87.963280\n",
            " 23266/50000: episode: 187, duration: 1.167s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.171 [-0.957, 0.922], loss: 8.136737, mae: 44.231178, mean_q: 88.955452\n",
            " 23466/50000: episode: 188, duration: 1.183s, episode steps: 200, steps per second: 169, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: -0.050 [-1.395, 1.816], loss: 13.617123, mae: 44.698856, mean_q: 89.609901\n",
            " 23666/50000: episode: 189, duration: 1.156s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.001 [-1.705, 1.332], loss: 15.017930, mae: 44.836037, mean_q: 89.693146\n",
            " 23866/50000: episode: 190, duration: 1.177s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.007 [-0.917, 0.957], loss: 19.100431, mae: 45.156616, mean_q: 90.205139\n",
            " 24066/50000: episode: 191, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.021 [-1.135, 1.070], loss: 12.458242, mae: 45.202206, mean_q: 90.396660\n",
            " 24266/50000: episode: 192, duration: 1.179s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.037 [-1.280, 1.157], loss: 13.040947, mae: 45.679920, mean_q: 91.450508\n",
            " 24466/50000: episode: 193, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.015 [-1.111, 1.010], loss: 11.580366, mae: 45.732254, mean_q: 91.568535\n",
            " 24666/50000: episode: 194, duration: 1.157s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.039 [-1.373, 1.680], loss: 10.942246, mae: 45.750919, mean_q: 91.494484\n",
            " 24866/50000: episode: 195, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.034 [-1.317, 1.327], loss: 14.473699, mae: 46.080021, mean_q: 91.999069\n",
            " 25066/50000: episode: 196, duration: 1.176s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.017 [-1.127, 1.026], loss: 11.437606, mae: 45.972260, mean_q: 91.819115\n",
            " 25266/50000: episode: 197, duration: 1.169s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.014 [-1.710, 1.579], loss: 15.226871, mae: 45.763790, mean_q: 91.249054\n",
            " 25466/50000: episode: 198, duration: 1.165s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.011 [-1.353, 1.258], loss: 13.201455, mae: 46.028057, mean_q: 91.885635\n",
            " 25666/50000: episode: 199, duration: 1.171s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.026 [-1.140, 1.195], loss: 21.320257, mae: 46.490719, mean_q: 92.602020\n",
            " 25866/50000: episode: 200, duration: 1.171s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.019 [-1.182, 1.343], loss: 15.000350, mae: 46.436924, mean_q: 92.623962\n",
            " 26066/50000: episode: 201, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.021 [-1.370, 1.492], loss: 22.591585, mae: 46.539658, mean_q: 92.552933\n",
            " 26266/50000: episode: 202, duration: 1.194s, episode steps: 200, steps per second: 168, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.009 [-1.524, 1.448], loss: 13.967223, mae: 46.407394, mean_q: 92.599510\n",
            " 26466/50000: episode: 203, duration: 1.151s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.031 [-0.944, 1.173], loss: 19.081034, mae: 46.425953, mean_q: 92.502968\n",
            " 26666/50000: episode: 204, duration: 1.150s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.016 [-1.093, 0.835], loss: 16.278156, mae: 46.260727, mean_q: 92.171638\n",
            " 26866/50000: episode: 205, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.012 [-1.233, 1.507], loss: 20.166275, mae: 46.331112, mean_q: 92.243187\n",
            " 27066/50000: episode: 206, duration: 1.155s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.030 [-1.514, 1.645], loss: 30.076197, mae: 46.461536, mean_q: 92.217773\n",
            " 27266/50000: episode: 207, duration: 1.171s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.030 [-1.152, 1.158], loss: 21.407803, mae: 46.316143, mean_q: 92.252792\n",
            " 27393/50000: episode: 208, duration: 0.731s, episode steps: 127, steps per second: 174, episode reward: 127.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: 0.012 [-1.309, 1.475], loss: 26.215689, mae: 46.302322, mean_q: 92.099731\n",
            " 27593/50000: episode: 209, duration: 1.166s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.485 [0.000, 1.000], mean observation: 0.015 [-1.239, 1.259], loss: 18.649803, mae: 46.178577, mean_q: 92.034630\n",
            " 27793/50000: episode: 210, duration: 1.156s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.001 [-1.044, 1.098], loss: 15.434013, mae: 46.178349, mean_q: 92.096306\n",
            " 27993/50000: episode: 211, duration: 1.184s, episode steps: 200, steps per second: 169, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.003 [-1.463, 1.302], loss: 18.814804, mae: 46.143143, mean_q: 91.826302\n",
            " 28193/50000: episode: 212, duration: 1.167s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.005 [-1.435, 1.496], loss: 18.800404, mae: 46.168072, mean_q: 91.955490\n",
            " 28341/50000: episode: 213, duration: 0.848s, episode steps: 148, steps per second: 174, episode reward: 148.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.004 [-1.512, 1.980], loss: 22.860182, mae: 46.462120, mean_q: 92.334984\n",
            " 28541/50000: episode: 214, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.006 [-1.703, 1.418], loss: 16.389572, mae: 46.361729, mean_q: 92.448425\n",
            " 28616/50000: episode: 215, duration: 0.434s, episode steps: 75, steps per second: 173, episode reward: 75.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.467 [0.000, 1.000], mean observation: -0.049 [-1.503, 1.720], loss: 21.183958, mae: 46.216782, mean_q: 91.885422\n",
            " 28816/50000: episode: 216, duration: 1.152s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.025 [-1.485, 1.209], loss: 12.723841, mae: 46.121464, mean_q: 92.111702\n",
            " 28980/50000: episode: 217, duration: 2.440s, episode steps: 164, steps per second: 67, episode reward: 164.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: -0.031 [-1.359, 1.449], loss: 27.146187, mae: 46.051224, mean_q: 91.436142\n",
            " 29180/50000: episode: 218, duration: 1.197s, episode steps: 200, steps per second: 167, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.012 [-1.579, 1.299], loss: 14.641326, mae: 45.712677, mean_q: 91.153542\n",
            " 29380/50000: episode: 219, duration: 1.147s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.062 [-1.225, 1.358], loss: 20.306074, mae: 45.659767, mean_q: 90.914574\n",
            " 29580/50000: episode: 220, duration: 1.150s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.047 [-1.418, 1.443], loss: 15.141382, mae: 45.434113, mean_q: 90.636482\n",
            " 29683/50000: episode: 221, duration: 0.604s, episode steps: 103, steps per second: 170, episode reward: 103.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.076 [-1.371, 1.327], loss: 22.995504, mae: 45.357555, mean_q: 90.216888\n",
            " 29883/50000: episode: 222, duration: 1.162s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.025 [-1.320, 0.983], loss: 25.287153, mae: 45.126720, mean_q: 89.632980\n",
            " 30083/50000: episode: 223, duration: 1.163s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.087 [-1.469, 1.259], loss: 20.014927, mae: 44.722813, mean_q: 89.035011\n",
            " 30283/50000: episode: 224, duration: 1.155s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.169 [-1.503, 1.137], loss: 19.617523, mae: 44.161991, mean_q: 87.872696\n",
            " 30483/50000: episode: 225, duration: 1.154s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.024 [-1.074, 0.728], loss: 17.820898, mae: 43.346302, mean_q: 86.324280\n",
            " 30683/50000: episode: 226, duration: 1.159s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.074 [-1.390, 1.154], loss: 24.753487, mae: 42.922237, mean_q: 85.246429\n",
            " 30883/50000: episode: 227, duration: 1.186s, episode steps: 200, steps per second: 169, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.052 [-1.191, 1.029], loss: 13.853773, mae: 42.554688, mean_q: 84.861053\n",
            " 31083/50000: episode: 228, duration: 1.176s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.049 [-1.152, 0.978], loss: 11.592583, mae: 42.465370, mean_q: 84.757462\n",
            " 31283/50000: episode: 229, duration: 1.157s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: 0.034 [-1.550, 1.363], loss: 11.895273, mae: 42.426605, mean_q: 84.759232\n",
            " 31483/50000: episode: 230, duration: 1.152s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.022 [-1.177, 1.031], loss: 14.906990, mae: 42.376225, mean_q: 84.465759\n",
            " 31683/50000: episode: 231, duration: 1.163s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.016 [-1.212, 1.095], loss: 19.150139, mae: 42.299400, mean_q: 84.132034\n",
            " 31883/50000: episode: 232, duration: 1.165s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.016 [-1.415, 1.291], loss: 16.380377, mae: 41.909618, mean_q: 83.464401\n",
            " 31996/50000: episode: 233, duration: 0.670s, episode steps: 113, steps per second: 169, episode reward: 113.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.513 [0.000, 1.000], mean observation: 0.035 [-1.760, 1.492], loss: 16.759428, mae: 41.874893, mean_q: 83.334656\n",
            " 32196/50000: episode: 234, duration: 1.166s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.032 [-1.210, 1.139], loss: 14.670957, mae: 41.779755, mean_q: 83.293831\n",
            " 32242/50000: episode: 235, duration: 0.273s, episode steps: 46, steps per second: 168, episode reward: 46.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.522 [0.000, 1.000], mean observation: 0.036 [-1.400, 1.172], loss: 16.372875, mae: 41.827568, mean_q: 83.250298\n",
            " 32281/50000: episode: 236, duration: 0.259s, episode steps: 39, steps per second: 151, episode reward: 39.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.564 [0.000, 1.000], mean observation: 0.053 [-1.715, 1.483], loss: 6.923125, mae: 41.792850, mean_q: 83.738617\n",
            " 32425/50000: episode: 237, duration: 0.845s, episode steps: 144, steps per second: 170, episode reward: 144.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.521 [0.000, 1.000], mean observation: 0.038 [-2.252, 1.948], loss: 18.118217, mae: 42.103760, mean_q: 83.821785\n",
            " 32465/50000: episode: 238, duration: 0.257s, episode steps: 40, steps per second: 156, episode reward: 40.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.550 [0.000, 1.000], mean observation: 0.056 [-1.417, 1.294], loss: 16.260120, mae: 42.256847, mean_q: 83.886978\n",
            " 32585/50000: episode: 239, duration: 0.726s, episode steps: 120, steps per second: 165, episode reward: 120.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.517 [0.000, 1.000], mean observation: 0.030 [-1.606, 1.495], loss: 10.994006, mae: 42.046608, mean_q: 83.923988\n",
            " 32637/50000: episode: 240, duration: 0.317s, episode steps: 52, steps per second: 164, episode reward: 52.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.538 [0.000, 1.000], mean observation: 0.047 [-1.669, 1.532], loss: 10.914165, mae: 42.134476, mean_q: 84.168228\n",
            " 32681/50000: episode: 241, duration: 0.257s, episode steps: 44, steps per second: 171, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.055 [-1.632, 1.522], loss: 14.351737, mae: 42.230389, mean_q: 84.282181\n",
            " 32728/50000: episode: 242, duration: 0.277s, episode steps: 47, steps per second: 170, episode reward: 47.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.532 [0.000, 1.000], mean observation: 0.051 [-1.818, 1.671], loss: 16.287119, mae: 41.878452, mean_q: 83.400322\n",
            " 32928/50000: episode: 243, duration: 1.163s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.047 [-2.027, 1.770], loss: 12.359519, mae: 42.059532, mean_q: 84.032951\n",
            " 32972/50000: episode: 244, duration: 0.268s, episode steps: 44, steps per second: 164, episode reward: 44.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.545 [0.000, 1.000], mean observation: 0.068 [-1.619, 1.672], loss: 15.824405, mae: 42.154160, mean_q: 84.171417\n",
            " 33172/50000: episode: 245, duration: 1.163s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.062 [-1.777, 1.666], loss: 10.410936, mae: 41.936104, mean_q: 84.177147\n",
            " 33372/50000: episode: 246, duration: 1.170s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.087 [-1.251, 1.290], loss: 12.401050, mae: 42.010517, mean_q: 84.418434\n",
            " 33572/50000: episode: 247, duration: 1.150s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.110 [-1.033, 1.156], loss: 10.031250, mae: 41.584892, mean_q: 83.769821\n",
            " 33772/50000: episode: 248, duration: 1.152s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.225 [-1.021, 1.606], loss: 15.339370, mae: 41.486168, mean_q: 83.456581\n",
            " 33967/50000: episode: 249, duration: 1.121s, episode steps: 195, steps per second: 174, episode reward: 195.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.487 [0.000, 1.000], mean observation: 0.199 [-1.059, 2.518], loss: 11.637565, mae: 40.631695, mean_q: 81.792427\n",
            " 34129/50000: episode: 250, duration: 0.943s, episode steps: 162, steps per second: 172, episode reward: 162.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.224 [-1.070, 1.160], loss: 12.146291, mae: 40.246159, mean_q: 80.844147\n",
            " 34295/50000: episode: 251, duration: 0.992s, episode steps: 166, steps per second: 167, episode reward: 166.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.488 [0.000, 1.000], mean observation: 0.214 [-0.817, 2.302], loss: 9.310553, mae: 39.590302, mean_q: 79.569901\n",
            " 34495/50000: episode: 252, duration: 1.159s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.145 [-0.882, 0.936], loss: 9.431250, mae: 39.211681, mean_q: 78.772728\n",
            " 34663/50000: episode: 253, duration: 0.974s, episode steps: 168, steps per second: 172, episode reward: 168.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.494 [0.000, 1.000], mean observation: 0.211 [-0.871, 1.515], loss: 11.591852, mae: 38.642868, mean_q: 77.651413\n",
            " 34863/50000: episode: 254, duration: 1.167s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.165 [-0.871, 0.944], loss: 10.435713, mae: 38.062672, mean_q: 76.431564\n",
            " 35063/50000: episode: 255, duration: 1.152s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.098 [-0.926, 0.839], loss: 8.862545, mae: 38.070927, mean_q: 76.412537\n",
            " 35263/50000: episode: 256, duration: 1.179s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.062 [-1.108, 0.991], loss: 9.376941, mae: 38.502735, mean_q: 77.386627\n",
            " 35463/50000: episode: 257, duration: 1.169s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.105 [-1.099, 0.997], loss: 7.702606, mae: 38.932850, mean_q: 78.290375\n",
            " 35663/50000: episode: 258, duration: 1.182s, episode steps: 200, steps per second: 169, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.058 [-0.791, 0.893], loss: 12.191760, mae: 38.769989, mean_q: 77.907478\n",
            " 35863/50000: episode: 259, duration: 1.190s, episode steps: 200, steps per second: 168, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.043 [-0.923, 0.760], loss: 9.950195, mae: 39.231026, mean_q: 78.839798\n",
            " 36063/50000: episode: 260, duration: 1.149s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.073 [-1.386, 1.292], loss: 10.646536, mae: 39.537148, mean_q: 79.550476\n",
            " 36263/50000: episode: 261, duration: 1.157s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.042 [-1.060, 1.036], loss: 10.041430, mae: 39.513538, mean_q: 79.626686\n",
            " 36463/50000: episode: 262, duration: 1.148s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.030 [-1.142, 0.952], loss: 10.903195, mae: 39.778595, mean_q: 80.016495\n",
            " 36663/50000: episode: 263, duration: 1.190s, episode steps: 200, steps per second: 168, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.036 [-0.985, 1.120], loss: 12.940023, mae: 40.156185, mean_q: 80.763771\n",
            " 36863/50000: episode: 264, duration: 1.167s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.026 [-1.174, 0.942], loss: 10.296642, mae: 40.278412, mean_q: 81.056931\n",
            " 37063/50000: episode: 265, duration: 1.159s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.025 [-1.544, 1.294], loss: 11.310855, mae: 40.445751, mean_q: 81.309578\n",
            " 37263/50000: episode: 266, duration: 1.190s, episode steps: 200, steps per second: 168, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.043 [-1.258, 1.080], loss: 10.776821, mae: 40.496891, mean_q: 81.352951\n",
            " 37463/50000: episode: 267, duration: 1.171s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.055 [-1.644, 1.787], loss: 14.840576, mae: 40.701019, mean_q: 81.721481\n",
            " 37663/50000: episode: 268, duration: 1.196s, episode steps: 200, steps per second: 167, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.030 [-0.896, 0.946], loss: 11.077204, mae: 40.817318, mean_q: 81.964577\n",
            " 37863/50000: episode: 269, duration: 1.147s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.055 [-1.400, 1.426], loss: 10.938264, mae: 41.163116, mean_q: 82.524826\n",
            " 38063/50000: episode: 270, duration: 1.146s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.040 [-0.938, 0.792], loss: 13.271222, mae: 41.236584, mean_q: 82.505333\n",
            " 38263/50000: episode: 271, duration: 1.151s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.034 [-1.028, 0.897], loss: 13.431582, mae: 41.573593, mean_q: 83.029251\n",
            " 38463/50000: episode: 272, duration: 1.153s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.027 [-1.252, 0.988], loss: 12.337811, mae: 41.582397, mean_q: 83.008575\n",
            " 38663/50000: episode: 273, duration: 1.165s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.034 [-1.162, 1.122], loss: 11.785330, mae: 42.340542, mean_q: 84.506073\n",
            " 38863/50000: episode: 274, duration: 1.146s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.080 [-1.329, 1.350], loss: 13.252732, mae: 42.862091, mean_q: 85.417503\n",
            " 39063/50000: episode: 275, duration: 1.140s, episode steps: 200, steps per second: 176, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.037 [-1.595, 1.374], loss: 18.182884, mae: 43.193932, mean_q: 85.871346\n",
            " 39263/50000: episode: 276, duration: 1.126s, episode steps: 200, steps per second: 178, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.043 [-1.639, 1.493], loss: 13.933558, mae: 43.470047, mean_q: 86.577263\n",
            " 39463/50000: episode: 277, duration: 1.164s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: 0.043 [-1.257, 1.157], loss: 15.129656, mae: 43.932373, mean_q: 87.448029\n",
            " 39663/50000: episode: 278, duration: 1.163s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.094 [-1.030, 1.242], loss: 17.952873, mae: 44.180565, mean_q: 87.849113\n",
            " 39863/50000: episode: 279, duration: 1.144s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.161 [-1.594, 1.487], loss: 17.145447, mae: 44.137974, mean_q: 87.689873\n",
            " 40063/50000: episode: 280, duration: 1.166s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.136 [-1.487, 1.531], loss: 16.004023, mae: 43.968853, mean_q: 87.548981\n",
            " 40263/50000: episode: 281, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.034 [-1.069, 1.025], loss: 17.385435, mae: 43.745285, mean_q: 87.071754\n",
            " 40463/50000: episode: 282, duration: 1.157s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.015 [-1.480, 1.599], loss: 21.896797, mae: 43.883018, mean_q: 87.096115\n",
            " 40663/50000: episode: 283, duration: 1.145s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.016 [-1.546, 1.730], loss: 10.960369, mae: 44.110764, mean_q: 88.028427\n",
            " 40863/50000: episode: 284, duration: 1.163s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: 0.040 [-1.343, 1.143], loss: 19.592424, mae: 44.157677, mean_q: 87.783791\n",
            " 41063/50000: episode: 285, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.019 [-1.665, 1.390], loss: 18.622028, mae: 44.120373, mean_q: 87.759064\n",
            " 41244/50000: episode: 286, duration: 1.045s, episode steps: 181, steps per second: 173, episode reward: 181.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.503 [0.000, 1.000], mean observation: 0.026 [-1.385, 1.566], loss: 26.878157, mae: 44.239491, mean_q: 87.795441\n",
            " 41444/50000: episode: 287, duration: 1.197s, episode steps: 200, steps per second: 167, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.510 [0.000, 1.000], mean observation: 0.017 [-1.201, 1.617], loss: 14.610737, mae: 43.997799, mean_q: 87.827950\n",
            " 41644/50000: episode: 288, duration: 1.152s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.042 [-1.182, 1.187], loss: 13.097815, mae: 43.996964, mean_q: 87.865387\n",
            " 41844/50000: episode: 289, duration: 1.169s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.041 [-1.232, 1.232], loss: 16.634008, mae: 43.880962, mean_q: 87.643730\n",
            " 42044/50000: episode: 290, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.043 [-1.282, 1.238], loss: 13.563882, mae: 43.498360, mean_q: 86.917191\n",
            " 42244/50000: episode: 291, duration: 1.153s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.520 [0.000, 1.000], mean observation: 0.024 [-1.599, 1.569], loss: 13.785290, mae: 43.377060, mean_q: 86.688828\n",
            " 42444/50000: episode: 292, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: 0.022 [-1.181, 1.103], loss: 12.815398, mae: 43.566368, mean_q: 87.159821\n",
            " 42535/50000: episode: 293, duration: 0.532s, episode steps: 91, steps per second: 171, episode reward: 91.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.011 [-1.084, 1.200], loss: 13.931211, mae: 43.330627, mean_q: 86.721901\n",
            " 42735/50000: episode: 294, duration: 1.168s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.004 [-1.270, 1.496], loss: 19.255020, mae: 43.519756, mean_q: 86.862579\n",
            " 42935/50000: episode: 295, duration: 1.175s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.019 [-1.734, 1.485], loss: 7.594678, mae: 43.474442, mean_q: 87.199730\n",
            " 43135/50000: episode: 296, duration: 1.154s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.005 [-1.431, 1.077], loss: 16.144402, mae: 44.139454, mean_q: 88.172638\n",
            " 43335/50000: episode: 297, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.002 [-1.155, 1.277], loss: 17.729414, mae: 44.022266, mean_q: 87.996368\n",
            " 43535/50000: episode: 298, duration: 1.144s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.011 [-1.104, 1.233], loss: 9.696847, mae: 44.270508, mean_q: 88.778320\n",
            " 43735/50000: episode: 299, duration: 1.155s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.047 [-1.374, 1.451], loss: 19.089554, mae: 44.539894, mean_q: 88.960648\n",
            " 43935/50000: episode: 300, duration: 1.147s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.012 [-1.340, 1.235], loss: 14.498589, mae: 44.770584, mean_q: 89.593643\n",
            " 44135/50000: episode: 301, duration: 1.148s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.018 [-1.018, 1.144], loss: 13.442473, mae: 45.234940, mean_q: 90.642365\n",
            " 44335/50000: episode: 302, duration: 1.148s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.043 [-0.979, 1.232], loss: 17.819725, mae: 45.533356, mean_q: 91.019699\n",
            " 44408/50000: episode: 303, duration: 0.425s, episode steps: 73, steps per second: 172, episode reward: 73.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.493 [0.000, 1.000], mean observation: -0.048 [-1.205, 1.481], loss: 14.662041, mae: 45.499046, mean_q: 91.263824\n",
            " 44551/50000: episode: 304, duration: 0.828s, episode steps: 143, steps per second: 173, episode reward: 143.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.483 [0.000, 1.000], mean observation: -0.055 [-1.313, 1.785], loss: 22.046478, mae: 45.843456, mean_q: 91.669907\n",
            " 44751/50000: episode: 305, duration: 1.150s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.054 [-1.211, 1.665], loss: 16.594013, mae: 46.133133, mean_q: 92.342331\n",
            " 44951/50000: episode: 306, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.515 [0.000, 1.000], mean observation: -0.059 [-1.480, 1.278], loss: 16.471174, mae: 46.769039, mean_q: 93.652435\n",
            " 45151/50000: episode: 307, duration: 1.160s, episode steps: 200, steps per second: 172, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.064 [-0.912, 1.136], loss: 17.710905, mae: 47.265038, mean_q: 94.629982\n",
            " 45351/50000: episode: 308, duration: 1.136s, episode steps: 200, steps per second: 176, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.079 [-1.362, 1.568], loss: 21.805574, mae: 47.242813, mean_q: 94.418495\n",
            " 45551/50000: episode: 309, duration: 1.156s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.074 [-0.954, 0.800], loss: 20.659433, mae: 47.172695, mean_q: 94.313431\n",
            " 45751/50000: episode: 310, duration: 1.159s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.095 [-0.958, 0.863], loss: 25.483881, mae: 46.856850, mean_q: 93.333466\n",
            " 45951/50000: episode: 311, duration: 1.150s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.057 [-0.955, 0.928], loss: 16.983288, mae: 46.657970, mean_q: 93.260811\n",
            " 46151/50000: episode: 312, duration: 1.174s, episode steps: 200, steps per second: 170, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.038 [-0.908, 0.944], loss: 16.552509, mae: 46.731651, mean_q: 93.535683\n",
            " 46351/50000: episode: 313, duration: 1.159s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.083 [-0.763, 0.723], loss: 13.129498, mae: 46.740780, mean_q: 93.596642\n",
            " 46551/50000: episode: 314, duration: 1.232s, episode steps: 200, steps per second: 162, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.092 [-0.839, 0.836], loss: 20.401762, mae: 46.477615, mean_q: 92.982071\n",
            " 46751/50000: episode: 315, duration: 1.202s, episode steps: 200, steps per second: 166, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.126 [-1.163, 0.809], loss: 23.987446, mae: 46.148224, mean_q: 92.066559\n",
            " 46951/50000: episode: 316, duration: 1.236s, episode steps: 200, steps per second: 162, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.092 [-1.055, 0.865], loss: 17.057045, mae: 45.844791, mean_q: 91.633408\n",
            " 47151/50000: episode: 317, duration: 1.208s, episode steps: 200, steps per second: 166, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.131 [-1.057, 0.921], loss: 20.746162, mae: 45.191429, mean_q: 90.147255\n",
            " 47351/50000: episode: 318, duration: 1.195s, episode steps: 200, steps per second: 167, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.106 [-0.857, 0.682], loss: 12.470879, mae: 44.973667, mean_q: 89.960800\n",
            " 47551/50000: episode: 319, duration: 1.182s, episode steps: 200, steps per second: 169, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.092 [-0.823, 0.701], loss: 19.574398, mae: 44.769146, mean_q: 89.291328\n",
            " 47751/50000: episode: 320, duration: 1.167s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.077 [-1.214, 0.896], loss: 14.698239, mae: 44.069027, mean_q: 87.994942\n",
            " 47951/50000: episode: 321, duration: 1.142s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.061 [-0.974, 1.032], loss: 18.605658, mae: 43.955391, mean_q: 87.579002\n",
            " 48151/50000: episode: 322, duration: 1.134s, episode steps: 200, steps per second: 176, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.025 [-0.727, 0.856], loss: 15.788364, mae: 43.594288, mean_q: 86.905869\n",
            " 48351/50000: episode: 323, duration: 1.125s, episode steps: 200, steps per second: 178, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.015 [-1.054, 0.926], loss: 13.958942, mae: 43.537857, mean_q: 86.850967\n",
            " 48551/50000: episode: 324, duration: 1.142s, episode steps: 200, steps per second: 175, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.490 [0.000, 1.000], mean observation: -0.028 [-1.026, 1.109], loss: 14.327335, mae: 43.310837, mean_q: 86.399841\n",
            " 48751/50000: episode: 325, duration: 1.172s, episode steps: 200, steps per second: 171, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.020 [-0.850, 1.008], loss: 16.590435, mae: 43.321098, mean_q: 86.372490\n",
            " 48951/50000: episode: 326, duration: 1.154s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.014 [-0.940, 0.844], loss: 17.767918, mae: 43.346260, mean_q: 86.363007\n",
            " 49151/50000: episode: 327, duration: 1.152s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.003 [-1.118, 0.864], loss: 14.387371, mae: 43.059006, mean_q: 85.930626\n",
            " 49351/50000: episode: 328, duration: 1.153s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: -0.002 [-0.995, 1.116], loss: 13.593413, mae: 43.459053, mean_q: 86.792870\n",
            " 49551/50000: episode: 329, duration: 1.147s, episode steps: 200, steps per second: 174, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.495 [0.000, 1.000], mean observation: -0.052 [-0.943, 0.880], loss: 12.955636, mae: 43.544621, mean_q: 87.006081\n",
            " 49751/50000: episode: 330, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.500 [0.000, 1.000], mean observation: -0.001 [-0.945, 0.977], loss: 11.920215, mae: 43.881664, mean_q: 87.679276\n",
            " 49951/50000: episode: 331, duration: 1.158s, episode steps: 200, steps per second: 173, episode reward: 200.000, mean reward: 1.000 [1.000, 1.000], mean action: 0.505 [0.000, 1.000], mean observation: 0.006 [-1.031, 0.773], loss: 11.676028, mae: 43.984932, mean_q: 87.849121\n",
            "done, took 298.445 seconds\n",
            "Testing for 5 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgwrTjIQ7UV9"
      },
      "source": [
        "# Results\r\n",
        "\r\n",
        "I see the results using matplotlib and defining and auxiliar function that print a plot for each metric inside the history object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMAUFXbP8aoI"
      },
      "source": [
        "def plot_history(history):\r\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(16,4))\r\n",
        "  for i, key in enumerate(history.history.keys()):\r\n",
        "    axes[i].plot(list(range(len(history.history[key]))), history.history[key])\r\n",
        "    axes[i].set_title(key)\r\n",
        "    axes[i].set_xlabel('episode')\r\n",
        "  plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "AVRyuxNM8lsf",
        "outputId": "97ca23ec-f783-42d4-e10a-c73e0aa198f0"
      },
      "source": [
        "plot_history(train_history)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0XgIHbScS8rB",
        "outputId": "ffa5572f-38c4-4a14-97e4-6a29371b6f4d"
      },
      "source": [
        "plot_history(test_history)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}